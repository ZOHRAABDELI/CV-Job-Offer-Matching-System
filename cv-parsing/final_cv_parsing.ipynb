{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 : Extract 1 CV"
      ],
      "metadata": {
        "id": "xbqzpfJkmCb_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elzscw2_hmxi",
        "outputId": "0930cb97-26a6-4a08-d134-50a4fd463674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tika in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tika) (75.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tika) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tika) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tika) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tika) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tika) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "# prompt: install tika\n",
        "!pip install tika"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Start the server (first import triggers Java download and setup)\n",
        "from tika import parser\n",
        "from tika import initVM\n",
        "initVM()  # Explicitly initialize Java VM (optional but safer)\n"
      ],
      "metadata": {
        "id": "u-xfpZSghvPx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import requests\n"
      ],
      "metadata": {
        "id": "W0LO3MTAhxSc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_pdf_content(file_path):\n",
        "    \"\"\"\n",
        "    Extract text content from a PDF file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the PDF file\n",
        "\n",
        "    Returns:\n",
        "        str: Extracted text content or None if extraction failed\n",
        "    \"\"\"\n",
        "    parsed = parser.from_file(file_path)\n",
        "    content = parsed['content']\n",
        "    return content.strip() if content else None\n",
        "\n",
        "pdf_content = extract_pdf_content(\"1-Amine_SAIGHI.pdf\")\n",
        "print(pdf_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibM-2c0AhzB3",
        "outputId": "df33645f-1880-4e7b-d8ca-49b2c99bd77f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-15 20:41:16,188 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server-standard/3.1.0/tika-server-standard-3.1.0.jar to /tmp/tika-server.jar.\n",
            "INFO:tika.tika:Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server-standard/3.1.0/tika-server-standard-3.1.0.jar to /tmp/tika-server.jar.\n",
            "2025-04-15 20:41:20,229 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server-standard/3.1.0/tika-server-standard-3.1.0.jar.md5 to /tmp/tika-server.jar.md5.\n",
            "INFO:tika.tika:Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server-standard/3.1.0/tika-server-standard-3.1.0.jar.md5 to /tmp/tika-server.jar.md5.\n",
            "2025-04-15 20:41:21,316 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n",
            "WARNING:tika.tika:Failed to see startup log message; retrying...\n",
            "2025-04-15 20:41:26,321 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n",
            "WARNING:tika.tika:Failed to see startup log message; retrying...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AMINE \n",
            "SAIGHI \n",
            "\n",
            "Alger, Algérie   \n",
            "\n",
            "+213 661 282 545   \n",
            "\n",
            "amin.saighi@gmail.com   \n",
            "\n",
            "Amine SAIGHI  \n",
            "\n",
            "  \n",
            "\n",
            " RÉSUMÉ PROFESSIONNEL \n",
            "Un passionné de technologie, capable d'apprendre, de comprendre et de transformer les \n",
            "besoins métier en logiciels fiables et évolutifs conformes aux spécifications du client. \n",
            "\n",
            " COMPÉTENCES \n",
            "• Languages: C#, ASP.net, TS \n",
            "\n",
            "• Base de donnée : SQL Server, MySQL \n",
            "\n",
            "• Service web: RESTful \n",
            "\n",
            "• Frameworks: .Net Core, Angular, ReactJs, \n",
            "\n",
            "ABP Framework \n",
            "\n",
            "• Design system: Ant-Design (NgZorro), \n",
            "\n",
            "Bootstrap, Material UI \n",
            "\n",
            "• Software: VS 2022, MS SQL Server, \n",
            "\n",
            "VSCode, Postman, Git, GitHub desktop \n",
            "\n",
            "• Fortes capacités de résolution de \n",
            "\n",
            "problems \n",
            "\n",
            "• Bonnes compétences en \n",
            "\n",
            "communication \n",
            "\n",
            "• Capacité d'apprentissage rapide \n",
            "\n",
            " EDUCATION \n",
            "Master | en Ingénierie Logicielle | Université Constantine 2 \n",
            "2012 – 2014 \n",
            "\n",
            "License | en Ingénierie Logicielle | Université Constantine 2 \n",
            "2008 – 2012 \n",
            "\n",
            " FORMATIONS \n",
            "DEVELOPPEMENT AGILE AVEC SCRUM | ITCOMP | Alger - 12/2021 \n",
            "SCRUM | ITCOMP | Alger - 03/2021 \n",
            "Workshop: Building an enterprise application with ASP.NET Core MVC | \n",
            "ITCOMP | Alger - 02/2020 (TWO WEEKS) \n",
            "Developing ASP.net MVC Web App Course n°: 20486B | ITCOMP | Alger - \n",
            "02/2018 \n",
            "Training of trainers for the youth-peer program | Association Souk | \n",
            "Constantine - 01/2014 \n",
            "Programming in C# | ITCOMP | Alger - 10/2012 \n",
            "\n",
            " EXPÉRIENCE \n",
            "Ingénieur logiciel (Lead tech .Net) | Aladvise | Alger, Algérie (Télétravail – \n",
            "Paris, France) \n",
            "01-2022 – TODAY \n",
            "Mes responsabilités incluent:  \n",
            "\n",
            "• Lead tech, revues de code et développement de nouvelles solutions  \n",
            "\n",
            "\n",
            "\n",
            "2 \n",
            "\n",
            "• Développement et intégration de solutions informatiques  \n",
            "\n",
            "• Conseils, études et mise en place de systèmes d'information  \n",
            "\n",
            "PROJET: ScopDiffusion (broadcasting job-offer) \n",
            "\n",
            " \n",
            "\n",
            "MISSIONS:  \n",
            "\n",
            "• Étude et analyse de l'environnement du système  \n",
            "\n",
            "• Conception générale et détaillée documentée  \n",
            "\n",
            "• Développement \n",
            "\n",
            "STACK TECH : .Net 6 (dotnet 6), Entity Framework 6 (ORM) Clean architecture & clean code, \n",
            "N-Tier architecture (code design), SQL Server, Azure DevOps, ReactJS \n",
            "\n",
            " \n",
            "\n",
            "PROJET: ScopTalent (Applicant Tracking System) \n",
            "\n",
            " \n",
            "\n",
            "MISSIONS:  \n",
            "\n",
            "• Étude et analyse de l'environnement du système \n",
            "\n",
            "•  Débogage et développement \n",
            "\n",
            "STACK TECH: .Net framework 4.8, ASP.net 4.8, Azure DevOps \n",
            "\n",
            " \n",
            "\n",
            "Ingénieur logiciel | ITComp-DZ | Alger, Algérie \n",
            "02-2018 – 12-2021 \n",
            "Mes responsabilités incluaient:  \n",
            "\n",
            "• Développement et intégration de solutions informatiques  \n",
            "\n",
            "• Conseils, études et mise en place de systèmes d'information  \n",
            "\n",
            "• Formation et éventuellement conception de contenu de formation \n",
            "\n",
            "PROJET: PROJET INTERNE \n",
            "\n",
            " \n",
            "\n",
            "MISSIONS:  \n",
            "\n",
            "• Lead Tech \n",
            "\n",
            "• SCRUM Master \n",
            "\n",
            "• Étude et analyse de l'environnement du système \n",
            "\n",
            "• Conception générale et détaillée documentée \n",
            "\n",
            "• Développement \n",
            "\n",
            "STACK TECH: DDDesign, Dotnet basé sur le ABP Framework, Front End: Angular 10, Azure \n",
            "DevOps \n",
            "\n",
            " \n",
            "\n",
            "PROJET: CONCEPTION, DÉVELOPPEMENT ET INTÉGRATION D'UN SYSTÈME DE GESTION POUR \n",
            "LES DISPOSITIFS DAIP ET LA GESTION DES PAIEMENTS DANS LE SYSTÈME D'INFORMATION DE \n",
            "L'ANEM (AGENCE NATIONALE POUR L'EMPLOI) \n",
            "\n",
            " \n",
            "\n",
            "MISSIONS:  \n",
            "\n",
            "• Étude et analyse de l'environnement du système \n",
            "\n",
            "• Conception générale et détaillée documentée \n",
            "\n",
            "• Développement \n",
            "\n",
            "• Intégration et déploiement \n",
            "\n",
            "STACK TECH: N-Tier Architecture, IIS7 Web Server, OS Windows Server 2012 R2, Use of web \n",
            "services (REST), ASP.Net Framework 4.7 and Core2.1 - MS SQL 2014, 2017, Front End: Angular \n",
            "6, HTML5 CSS3 \n",
            "\n",
            "\n",
            "\n",
            "3 \n",
            "\n",
            " \n",
            "\n",
            "PROJET: PORTAIL ALGÉRIEN POUR LE HAJJ (PÈLERINAGE) \n",
            "\n",
            "MISSIONS: \n",
            "\n",
            "• Étude et analyse de l'environnement du système \n",
            "\n",
            "• Conception générale et détaillée documentée \n",
            "\n",
            "• Unit development and testing \n",
            "\n",
            "• Intégration et déploiement \n",
            "\n",
            "STACK TECH:  N-Tier Architecture, IIS7 Web Server, OS Windows Server 2012 R2, Use of web \n",
            "services (REST), ASP.Net Framework 4.7, MS SQL 2012, Front End: \n",
            "HTML5/CSS3/JS/JQuery/Razor \n",
            "\n",
            " \n",
            "\n",
            "Chef de Projet | Creative mustang | Constantine, Algérie \n",
            "2017 – 2018 \n",
            "Chef de projet dans une agence de communication numérique \n",
            "\n",
            "PROJET: CRÉATION DE SITE WEB ET SOLUTIONS DIGITALES SUR MESURE \n",
            "\n",
            "MISSIONS: \n",
            "\n",
            "• Développement de la marque et création de logo. \n",
            "\n",
            "• Création d'identité visuelle \n",
            "\n",
            "• Développement de site web \n",
            "\n",
            "• Impression de maquettes et de dépliants publicitaires \n",
            "\n",
            "• Développement et intégration de la gestion des stocks \n",
            "\n",
            "STACK TECH:  Windows, Adobe Photoshop Illustrator \n",
            "\n",
            " \n",
            "\n",
            "Ingénieur en assurance qualité| LDM-Groupe| Constantine, Algérie \n",
            "2015 – 2017 \n",
            "Ensure management procedures and protocols and work papers. \n",
            "\n",
            " \n",
            "\n",
            "PROJET: Assurer les procédures de gestion et les protocoles ainsi que les travaux écrits. \n",
            "\n",
            "MISSIONS: \n",
            "\n",
            "• Qualification et validation des systèmes informatiques \n",
            "\n",
            "• Audit interne \n",
            "\n",
            " EXTRA-PROFESSIONAL EXPERIENCE \n",
            "Vice-président Communication & Marketing| AIESEC in Constantine | \n",
            "Constantine, Algérie - 10-2013 – 06-2014 \n",
            "Chief Information Office| Google Developers Groups | Constantine, Algerie - \n",
            "06-2012 – 06-2013 \n",
            "Co-fondateur et membre| AIESEC in Constantine| Constantine, Algérie - 11-\n",
            "2012 – 08-2013 \n",
            "Responsable de la communication| Student Chapter at OWASP | Alger, \n",
            "Algérie - 2012 – 2013 \n",
            "\n",
            " ACTIVITÉS \n",
            "04/2013: Second STARTUP Prize in the National Institute of Telecommunications and \n",
            "Technologies of Information and Communication Oran. \n",
            "04/2012: First STARTUP prize at the incubator CyberParc Sidi Abdallah Alger \n",
            "\n",
            "\n",
            "\n",
            "4 \n",
            "\n",
            " LANGUES \n",
            "French: Maîtrise native ou bilingue \n",
            "\n",
            "English: Compétence professionnelle limitée \n",
            "\n",
            "Arabic: Maîtrise native ou bilingue \n",
            "\n",
            "German: Basic (A1, A2, B1) \n",
            "\n",
            " CENTRES D'INTÉRÊT \n",
            "Travail associatif, Musique, Sciences & Art, Chess, Sport, Sport électronique.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "def analyze_resume_with_qwen_json(resume_text, output_file=\"resume_data.json\"):\n",
        "    \"\"\"\n",
        "    Analyze a resume using Qwen and extract structured information in JSON format.\n",
        "    Updated to use a simplified extracurricular format.\n",
        "\n",
        "    Args:\n",
        "        resume_text: Raw text extracted from the resume.\n",
        "        output_file: Path to save the JSON output.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing the structured resume information.\n",
        "    \"\"\"\n",
        "    # Replace with your actual OpenRouter API key (preferably stored securely in environment variables)\n",
        "    OPENROUTER_API_KEY = \"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\"\n",
        "\n",
        "    # Correct endpoint for OpenRouter API\n",
        "    API_ENDPOINT = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"HTTP-Referer\": \"https://your-site-url.com\",  # Replace with your site URL\n",
        "        \"X-Title\": \"Resume Analyzer\",      # Replace with your site name\n",
        "    }\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You will receive a resume/CV in either English or French. Please extract all information and organize it into a structured JSON format.\n",
        "\n",
        "Your response must be ONLY valid JSON with the following structure:\n",
        "{{\n",
        "  \"personal_information\": {{\n",
        "    \"name\": \"\",\n",
        "    \"email\": \"\",\n",
        "    \"phone\": \"\",\n",
        "    \"address\": \"\",\n",
        "    \"linkedin\": \"\"\n",
        "  }},\n",
        "  \"summary\": [\n",
        "    \"Points from the summary or objective section\"\n",
        "  ],\n",
        "  \"education\": [\n",
        "    {{\n",
        "      \"degree\": \"\",\n",
        "      \"institution\": \"\",\n",
        "      \"period\": \"\"\n",
        "    }}\n",
        "  ],\n",
        "  \"work_experience\": [\n",
        "    {{\n",
        "      \"position\": \"\",\n",
        "      \"company\": \"\",\n",
        "      \"period\": \"\",\n",
        "      \"location\": \"\",\n",
        "      \"description\": \"\"\n",
        "    }}\n",
        "  ],\n",
        "  \"projects\": [\n",
        "    {{\n",
        "      \"name\": \"\",\n",
        "      \"description\": \"\"\n",
        "    }}\n",
        "  ],\n",
        "  \"skills\": {{\n",
        "    \"category1\": [\"skill1\", \"skill2\"],\n",
        "    \"category2\": [\"skill3\", \"skill4\"]\n",
        "  }},\n",
        "  \"languages\": [\n",
        "    {{\n",
        "      \"language\": \"\",\n",
        "      \"proficiency\": \"\"\n",
        "    }}\n",
        "  ],\n",
        "  \"certifications\": [\n",
        "    \"certification1\",\n",
        "    \"certification2\"\n",
        "  ],\n",
        "  \"publications\": [\n",
        "    \"publication1\",\n",
        "    \"publication2\"\n",
        "  ],\n",
        "  \"extracurricular\": [\n",
        "    \"activity1\",\n",
        "    \"activity2\",\n",
        "    \"activity3\"\n",
        "  ]\n",
        "}}\n",
        "\n",
        "Important instructions:\n",
        "- The content may be in English or French — keep the original language as is.\n",
        "- Your entire response must be ONLY the JSON object, with no explanations or additional text.\n",
        "- Include all sections in the JSON structure, even if they are empty.\n",
        "- Extract all relevant details from the document accurately.\n",
        "- Make sure the JSON is valid and properly formatted.\n",
        "- For extracurricular activities, provide them as a simple list of strings, not as categories.\n",
        "\n",
        "Resume Text:\n",
        "{resume_text}\n",
        "    \"\"\"\n",
        "\n",
        "    data = {\n",
        "        \"model\": \"qwen/qwen-2.5-72b-instruct\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ],\n",
        "        \"max_tokens\": 5000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(API_ENDPOINT, headers=headers, json=data)\n",
        "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "\n",
        "        completion = response.json()\n",
        "        content = completion[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "        # Extract JSON content if it's wrapped in markdown code blocks\n",
        "        if \"```json\" in content:\n",
        "            content = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "        elif \"```\" in content:\n",
        "            content = content.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "        # Parse the JSON content\n",
        "        resume_json = json.loads(content)\n",
        "\n",
        "        # Ensure the output directory exists\n",
        "        output_dir = os.path.dirname(output_file)\n",
        "        if output_dir and not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        # Save the JSON data to a file with explicit error handling\n",
        "        try:\n",
        "            with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(resume_json, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"Resume data successfully saved to {os.path.abspath(output_file)}\")\n",
        "        except Exception as save_error:\n",
        "            print(f\"Error saving file: {save_error}\")\n",
        "            # Try with a different path as fallback\n",
        "            fallback_path = os.path.join(os.getcwd(), \"resume_fallback.json\")\n",
        "            print(f\"Trying fallback path: {fallback_path}\")\n",
        "            with open(fallback_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(resume_json, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"Resume data saved to fallback path: {fallback_path}\")\n",
        "\n",
        "        return resume_json\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request error: {e}\")\n",
        "        if hasattr(e, 'response') and e.response:\n",
        "            print(f\"Status code: {e.response.status_code}\")\n",
        "            print(f\"Response text: {e.response.text}\")\n",
        "        return None\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON parse error: {e}\")\n",
        "        print(f\"Raw content received: {content if 'content' in locals() else 'No content available'}\")\n",
        "\n",
        "        # Try to extract JSON if it's in a malformed format\n",
        "        try:\n",
        "            # Find anything that looks like JSON\n",
        "            import re\n",
        "            json_pattern = r'\\{.*\\}'\n",
        "            match = re.search(json_pattern, content, re.DOTALL)\n",
        "            if match:\n",
        "                fixed_json = match.group(0)\n",
        "                resume_json = json.loads(fixed_json)\n",
        "\n",
        "                # If we succeeded in parsing, save it\n",
        "                with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(resume_json, f, ensure_ascii=False, indent=2)\n",
        "                print(f\"Fixed JSON saved to {output_file}\")\n",
        "                return resume_json\n",
        "        except Exception as recovery_error:\n",
        "            print(f\"Recovery attempt failed: {recovery_error}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "yVFXgfkemS2o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume_json = analyze_resume_with_qwen_json(pdf_content, \"output_resume.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djEi8IAFpSAV",
        "outputId": "6e60168b-e1c2-4c3c-acf0-0db415ebd703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume data successfully saved to /content/dehimi_yahia_resume.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 : Extract many Cvs and make it in one json file"
      ],
      "metadata": {
        "id": "vPjwnzavypYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**note :** you should run the function extract_pdf_content() from part 1 then run this"
      ],
      "metadata": {
        "id": "6k7p5yRENNdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Function to analyze a resume using Qwen ===\n",
        "def analyze_resume_with_qwen_json(resume_text):\n",
        "    OPENROUTER_API_KEY = \"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\"\n",
        "    API_ENDPOINT = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"HTTP-Referer\": \"https://your-site-url.com\",\n",
        "        \"X-Title\": \"Resume Analyzer\",\n",
        "    }\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You will receive a resume/CV in either English or French. Please extract all information and organize it into a structured JSON format.\n",
        "\n",
        "Your response must be ONLY valid JSON with the following structure:\n",
        "{{\n",
        "  \"personal_information\": {{\n",
        "    \"name\": \"\",\n",
        "    \"email\": \"\",\n",
        "    \"phone\": \"\",\n",
        "    \"address\": \"\",\n",
        "    \"linkedin\": \"\"\n",
        "  }},\n",
        "  \"summary\": [\n",
        "    \"Points from the summary or objective section\"\n",
        "  ],\n",
        "  \"education\": [\n",
        "    {{\n",
        "      \"degree\": \"\",\n",
        "      \"institution\": \"\",\n",
        "      \"period\": \"\"\n",
        "    }}\n",
        "  ],\n",
        "  \"work_experience\": [\n",
        "    {{\n",
        "      \"position\": \"\",\n",
        "      \"company\": \"\",\n",
        "      \"period\": \"\",\n",
        "      \"location\": \"\",\n",
        "      \"description\": \"\"\n",
        "    }}\n",
        "  ],\n",
        "  \"projects\": [\n",
        "    {{\n",
        "      \"name\": \"\",\n",
        "      \"description\": \"\"\n",
        "    }}\n",
        "  ],\n",
        "  \"skills\": {{\n",
        "    \"category1\": [\"skill1\", \"skill2\"],\n",
        "    \"category2\": [\"skill3\", \"skill4\"]\n",
        "  }},\n",
        "  \"languages\": [\n",
        "    {{\n",
        "      \"language\": \"\",\n",
        "      \"proficiency\": \"\"\n",
        "    }}\n",
        "  ],\n",
        "  \"certifications\": [\n",
        "    \"certification1\",\n",
        "    \"certification2\"\n",
        "  ],\n",
        "  \"publications\": [\n",
        "    \"publication1\",\n",
        "    \"publication2\"\n",
        "  ],\n",
        "  \"extracurricular\": [\n",
        "    \"activity1\",\n",
        "    \"activity2\",\n",
        "    \"activity3\"\n",
        "  ]\n",
        "}}\n",
        "\n",
        "Important instructions:\n",
        "- The content may be in English or French — keep the original language as is.\n",
        "- Your entire response must be ONLY the JSON object, with no explanations or additional text.\n",
        "- Include all sections in the JSON structure, even if they are empty.\n",
        "- Extract all relevant details from the document accurately.\n",
        "- Make sure the JSON is valid and properly formatted.\n",
        "\n",
        "Resume Text:\n",
        "{resume_text}\n",
        "    \"\"\"\n",
        "\n",
        "    data = {\n",
        "        \"model\": \"qwen/qwen-2.5-72b-instruct\",\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"max_tokens\": 5000\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(API_ENDPOINT, headers=headers, json=data)\n",
        "        response.raise_for_status()\n",
        "        content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "        if \"```json\" in content:\n",
        "            content = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "        elif \"```\" in content:\n",
        "            content = content.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "        return json.loads(content)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing resume: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "nOD2A8WuNlG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Function to process all resumes and create a single JSON file ===\n",
        "def process_all_resumes(folder_path, output_file=\"all_resumes.json\"):\n",
        "    all_resumes_data = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(folder_path, filename)\n",
        "            print(f\"Processing: {filename}\")\n",
        "\n",
        "            try:\n",
        "                text = extract_pdf_content(pdf_path)\n",
        "                data = analyze_resume_with_qwen_json(text)\n",
        "                if data:\n",
        "                    ordered_data = {\"file_name\": filename}\n",
        "                    ordered_data.update(data)  # Insert the rest of the JSON after the file name\n",
        "                    all_resumes_data.append(ordered_data)\n",
        "                else:\n",
        "                    print(f\"Failed to extract data from {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Exception while processing {filename}: {e}\")\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(all_resumes_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"\\n✅ All resumes processed and saved to: {os.path.abspath(output_file)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "J7lOOB-UpXBV",
        "outputId": "e8b78643-ae10-4642-9207-454dedb1c094"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: 1-Amine_SAIGHI.pdf\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5c5560bd6865>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content\"\u001b[0m  \u001b[0;31m# Replace with your actual folder name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mprocess_all_resumes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-5c5560bd6865>\u001b[0m in \u001b[0;36mprocess_all_resumes\u001b[0;34m(folder_path, output_file)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_pdf_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_resume_with_qwen_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0mordered_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"file_name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-e2671aa6a352>\u001b[0m in \u001b[0;36manalyze_resume_with_qwen_json\u001b[0;34m(resume_text)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPI_ENDPOINT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"choices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"message\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \"\"\"\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb\";\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === MAIN ===\n",
        "if __name__ == \"__main__\":\n",
        "    folder_path = \"/content\"  # Replace with your actual folder name( i said folder of many CVs not file )\n",
        "    process_all_resumes(folder_path)"
      ],
      "metadata": {
        "id": "bAWqhcrBzsEi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}